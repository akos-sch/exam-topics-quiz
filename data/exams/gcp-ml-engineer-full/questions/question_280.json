{
  "id": "question_280",
  "number": 280,
  "topic": "Topic 1",
  "text": "You are using Kubeflow Pipelines to develop an end-to-end PyTorch-based MLOps pipeline. The pipeline reads data from BigQuery, processes the data, conducts feature engineering, model training, model evaluation, and deploys the model as a binary file to Cloud Storage. You are writing code for several different versions of the feature engineering and model training steps, and running each new version in Vertex AI Pipelines. Each pipeline run is taking over an hour to complete. You want to speed up the pipeline execution to reduce your development time, and you want to avoid additional costs. What should you do?",
  "choices": [
    {
      "letter": "A",
      "text": "Comment out the part of the pipeline that you are not currently updating.",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "B",
      "text": "Enable caching in all the steps of the Kubeflow pipeline.",
      "is_most_voted": false,
      "is_correct": true
    },
    {
      "letter": "C",
      "text": "Delegate feature engineering to BigQuery and remove it from the pipeline.",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "D",
      "text": "Add a GPU to the model training step.",
      "is_most_voted": false,
      "is_correct": false
    }
  ],
  "correct_answer": "B",
  "explanation": "",
  "voting_data": {
    "total_votes": 7,
    "vote_distribution": {},
    "most_voted_answer": "B",
    "confidence_score": 1.0
  },
  "metadata": {
    "extraction_timestamp": "2025-05-29T12:25:15.394690",
    "source_url": "data/input/page-6.html",
    "page_number": 1,
    "difficulty_level": ""
  }
}
