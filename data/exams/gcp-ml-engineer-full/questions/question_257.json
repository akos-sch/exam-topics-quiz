{
  "id": "question_257",
  "number": 257,
  "topic": "Topic 1",
  "text": "You recently trained an XGBoost model on tabular data. You plan to expose the model for internal use as an HTTP microservice. After deployment, you expect a small number of incoming requests. You want to productionize the model with the least amount of effort and latency. What should you do?",
  "choices": [
    {
      "letter": "A",
      "text": "Deploy the model to BigQuery ML by using CREATE MODEL with the BOOSTED_TREE_REGRESSOR statement, and invoke the BigQuery API from the microservice.",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "B",
      "text": "Build a Flask-based app. Package the app in a custom container on Vertex AI, and deploy it to Vertex AI Endpoints.",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "C",
      "text": "Build a Flask-based app. Package the app in a Docker image, and deploy it to Google Kubernetes Engine in Autopilot mode.",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "D",
      "text": "Use a prebuilt XGBoost Vertex container to create a model, and deploy it to Vertex AI Endpoints.",
      "is_most_voted": false,
      "is_correct": true
    }
  ],
  "correct_answer": "D",
  "explanation": "",
  "voting_data": {
    "total_votes": 14,
    "vote_distribution": {},
    "most_voted_answer": "D",
    "confidence_score": 1.0
  },
  "metadata": {
    "extraction_timestamp": "2025-05-29T12:23:35.363578",
    "source_url": "data/input/page-6.html",
    "page_number": 1,
    "difficulty_level": ""
  }
}
