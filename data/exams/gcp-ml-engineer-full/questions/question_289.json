{
  "id": "question_289",
  "number": 289,
  "topic": "Topic 1",
  "text": "You developed a BigQuery ML linear regressor model by using a training dataset stored in a BigQuery table. New data is added to the table every minute. You are using Cloud Scheduler and Vertex AI Pipelines to automate hourly model training, and use the model for direct inference. The feature preprocessing logic includes quantile bucketization and MinMax scaling on data received in the last hour. You want to minimize storage and computational overhead. What should you do?",
  "choices": [
    {
      "letter": "A",
      "text": "Preprocess and stage the data in BigQuery prior to feeding it to the model during training and inference.",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "B",
      "text": "Use the TRANSFORM clause in the CREATE MODEL statement in the SQL query to calculate the required statistics.",
      "is_most_voted": true,
      "is_correct": true
    },
    {
      "letter": "C",
      "text": "Create a component in the Vertex AI Pipelines directed acyclic graph (DAG) to calculate the required statistics, and pass the statistics on to subsequent components.",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "D",
      "text": "Create SQL queries to calculate and store the required statistics in separate BigQuery tables that are referenced in the CREATE MODEL statement.",
      "is_most_voted": false,
      "is_correct": false
    }
  ],
  "correct_answer": "B",
  "explanation": "",
  "voting_data": {
    "total_votes": 9,
    "vote_distribution": {},
    "most_voted_answer": "B",
    "confidence_score": 0.5555555555555556
  },
  "metadata": {
    "extraction_timestamp": "2025-05-29T12:25:51.589845",
    "source_url": "data/input/page-6.html",
    "page_number": 1,
    "difficulty_level": ""
  }
}
