{
  "id": "question_131",
  "number": 131,
  "topic": "Topic 1",
  "text": "You are an ML engineer at a mobile gaming company. A data scientist on your team recently trained a TensorFlow model, and you are responsible for deploying this model into a mobile application. You discover that the inference latency of the current model doesnâ€™t meet production requirements. You need to reduce the inference time by 50%, and you are willing to accept a small decrease in model accuracy in order to reach the latency requirement. Without training a new model, which model optimization technique for reducing latency should you try first?",
  "choices": [
    {
      "letter": "A",
      "text": "Weight pruning",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "B",
      "text": "Dynamic range quantization",
      "is_most_voted": true,
      "is_correct": true
    },
    {
      "letter": "C",
      "text": "Model distillation",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "D",
      "text": "Dimensionality reduction",
      "is_most_voted": false,
      "is_correct": false
    }
  ],
  "correct_answer": "B",
  "explanation": "",
  "voting_data": {
    "total_votes": 14,
    "vote_distribution": {},
    "most_voted_answer": "B",
    "confidence_score": 1.0
  },
  "metadata": {
    "extraction_timestamp": "2025-05-29T12:13:54.387798",
    "source_url": "data/input/page-3.html",
    "page_number": 1,
    "difficulty_level": ""
  }
}
