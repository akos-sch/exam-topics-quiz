{
  "id": "question_242",
  "number": 242,
  "topic": "Topic 1",
  "text": "Your team is training a large number of ML models that use different algorithms, parameters, and datasets. Some models are trained in Vertex AI Pipelines, and some are trained on Vertex AI Workbench notebook instances. Your team wants to compare the performance of the models across both services. You want to minimize the effort required to store the parameters and metrics. What should you do?",
  "choices": [
    {
      "letter": "A",
      "text": "Implement an additional step for all the models running in pipelines and notebooks to export parameters and metrics to BigQuery.",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "B",
      "text": "Create a Vertex AI experiment. Submit all the pipelines as experiment runs. For models trained on notebooks log parameters and metrics by using the Vertex AI SDK.",
      "is_most_voted": false,
      "is_correct": true
    },
    {
      "letter": "C",
      "text": "Implement all models in Vertex AI Pipelines Create a Vertex AI experiment, and associate all pipeline runs with that experiment.",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "D",
      "text": "Store all model parameters and metrics as model metadata by using the Vertex AI Metadata API.",
      "is_most_voted": false,
      "is_correct": false
    }
  ],
  "correct_answer": "B",
  "explanation": "",
  "voting_data": {
    "total_votes": 13,
    "vote_distribution": {},
    "most_voted_answer": "B",
    "confidence_score": 0.923
  },
  "metadata": {
    "extraction_timestamp": "2025-05-29T12:22:19.845422",
    "source_url": "data/input/page-5.html",
    "page_number": 1,
    "difficulty_level": ""
  }
}
