{
  "id": "question_189",
  "number": 189,
  "topic": "Topic 1",
  "text": "You are implementing a batch inference ML pipeline in Google Cloud. The model was developed using TensorFlow and is stored in SavedModel format in Cloud Storage. You need to apply the model to a historical dataset containing 10 TB of data that is stored in a BigQuery table. How should you perform the inference?",
  "choices": [
    {
      "letter": "A",
      "text": "Export the historical data to Cloud Storage in Avro format. Configure a Vertex AI batch prediction job to generate predictions for the exported data",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "B",
      "text": "Import the TensorFlow model by using the CREATE MODEL statement in BigQuery ML. Apply the historical data to the TensorFlow model",
      "is_most_voted": true,
      "is_correct": true
    },
    {
      "letter": "C",
      "text": "Export the historical data to Cloud Storage in CSV format. Configure a Vertex AI batch prediction job to generate predictions for the exported data",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "D",
      "text": "Configure a Vertex AI batch prediction job to apply the model to the historical data in BigQuery",
      "is_most_voted": false,
      "is_correct": false
    }
  ],
  "correct_answer": "B",
  "explanation": "",
  "voting_data": {
    "total_votes": 22,
    "vote_distribution": {},
    "most_voted_answer": "B",
    "confidence_score": 0.7
  },
  "metadata": {
    "extraction_timestamp": "2025-05-29T12:18:25.452711",
    "source_url": "data/input/page-4.html",
    "page_number": 1,
    "difficulty_level": ""
  }
}
