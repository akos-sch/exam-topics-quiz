{
  "id": "question_213",
  "number": 213,
  "topic": "Topic 1",
  "text": "You are building a TensorFlow text-to-image generative model by using a dataset that contains billions of images with their respective captions. You want to create a low maintenance, automated workflow that reads the data from a Cloud Storage bucket collects statistics, splits the dataset into training/validation/test datasets performs data transformations trains the model using the training/validation datasets, and validates the model by using the test dataset. What should you do?",
  "choices": [
    {
      "letter": "A",
      "text": "Use the Apache Airflow SDK to create multiple operators that use Dataflow and Vertex AI services. Deploy the workflow on Cloud Composer.",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "B",
      "text": "Use the MLFlow SDK and deploy it on a Google Kubernetes Engine cluster. Create multiple components that use Dataflow and Vertex AI services.",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "C",
      "text": "Use the Kubeflow Pipelines (KFP) SDK to create multiple components that use Dataflow and Vertex AI services. Deploy the workflow on Vertex AI Pipelines.",
      "is_most_voted": false,
      "is_correct": false
    },
    {
      "letter": "D",
      "text": "Use the TensorFlow Extended (TFX) SDK to create multiple components that use Dataflow and Vertex AI services. Deploy the workflow on Vertex AI Pipelines.",
      "is_most_voted": false,
      "is_correct": true
    }
  ],
  "correct_answer": "D",
  "explanation": "",
  "voting_data": {
    "total_votes": 24,
    "vote_distribution": {},
    "most_voted_answer": "D",
    "confidence_score": 0.5
  },
  "metadata": {
    "extraction_timestamp": "2025-05-29T12:20:09.572265",
    "source_url": "data/input/page-5.html",
    "page_number": 1,
    "difficulty_level": ""
  }
}
